{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb76fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50f605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정 \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(2022)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(2022)\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e37f8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bf9c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (60000, 784), shape of y_train: (60000,)\n",
      "shape of x_test: (10000, 784) shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST('../../Deeplearning_dataset/MNIST/raw')\n",
    "\n",
    "x_train, y_train = mnist.load_training()\n",
    "x_test, y_test = mnist.load_testing()\n",
    "\n",
    "# list -> array\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(f\"shape of x_train: {x_train.shape}, shape of y_train: {y_train.shape}\")\n",
    "print(f\"shape of x_test: {x_test.shape} shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04307ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor로 변환후 x data와 y data 합치기\n",
    "train_data = data_utils.TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "test_data = data_utils.TensorDataset(torch.FloatTensor(x_test), torch.FloatTensor(y_test))\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "trainloader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "testloader = data_utils.DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2ca59",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c1cdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy_CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dummy_CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 64, 1, 1, 1),\n",
    "                                         torch.nn.BatchNorm2d(64),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(64, 128, 5, 2, 0),\n",
    "                                         torch.nn.BatchNorm2d(128),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        layer1_output = self.layer1(x)\n",
    "        layer2_output = self.layer2(layer1_output)\n",
    "        return layer2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd279716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 128, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data = torch.Tensor(1000, 1, 28, 28).to(device)\n",
    "dummy_model  = dummy_CNN().to(device)\n",
    "\n",
    "dummy_output = dummy_model(dummy_data)\n",
    "dummy_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bebe574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1152])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_output.view(batch_size, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f30eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 64, 1, 1, 1),\n",
    "                                         torch.nn.BatchNorm2d(64),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(64, 128, 5, 2, 0),\n",
    "                                         torch.nn.BatchNorm2d(128),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(2))\n",
    "        \n",
    "        self.fc = torch.nn.Linear(dummy_output.view(batch_size, -1).shape[-1], 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        layer1_output = self.layer1(x)\n",
    "        layer2_output = self.layer2(layer1_output)\n",
    "        \n",
    "        flatten = layer2_output.view(layer2_output.shape[0], -1) # fully-connected layer에 입력하기 위해서 일렬로 펴주는 기능\n",
    "        \n",
    "        output = self.fc(flatten)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8bb62e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d12cae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=1152, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f17629",
   "metadata": {},
   "source": [
    "## Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f19c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 15\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb673f61",
   "metadata": {},
   "source": [
    "## Loss Function, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257ea2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc09df",
   "metadata": {},
   "source": [
    "## Training, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95114faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] train_loss: 0.6427, train_accuracy: 83.93% / val_loss: 0.2408, val_accuracy: 93.75%\n",
      "Epoch [2] train_loss: 0.1983, train_accuracy: 94.97% / val_loss: 0.1561, val_accuracy: 95.92%\n",
      "Epoch [3] train_loss: 0.1409, train_accuracy: 96.33% / val_loss: 0.1191, val_accuracy: 96.56%\n",
      "Epoch [4] train_loss: 0.1127, train_accuracy: 97.08% / val_loss: 0.1002, val_accuracy: 97.28%\n",
      "Epoch [5] train_loss: 0.0966, train_accuracy: 97.46% / val_loss: 0.0949, val_accuracy: 97.19%\n",
      "Epoch [6] train_loss: 0.0857, train_accuracy: 97.67% / val_loss: 0.0776, val_accuracy: 97.79%\n",
      "Epoch [7] train_loss: 0.0756, train_accuracy: 97.99% / val_loss: 0.0715, val_accuracy: 97.90%\n",
      "Epoch [8] train_loss: 0.0692, train_accuracy: 98.10% / val_loss: 0.0663, val_accuracy: 98.00%\n",
      "Epoch [9] train_loss: 0.0630, train_accuracy: 98.31% / val_loss: 0.0661, val_accuracy: 97.97%\n",
      "Epoch [10] train_loss: 0.0577, train_accuracy: 98.40% / val_loss: 0.0613, val_accuracy: 98.10%\n",
      "Epoch [11] train_loss: 0.0545, train_accuracy: 98.52% / val_loss: 0.0601, val_accuracy: 98.22%\n",
      "Epoch [12] train_loss: 0.0505, train_accuracy: 98.58% / val_loss: 0.0561, val_accuracy: 98.36%\n",
      "Epoch [13] train_loss: 0.0471, train_accuracy: 98.70% / val_loss: 0.0554, val_accuracy: 98.21%\n",
      "Epoch [14] train_loss: 0.0445, train_accuracy: 98.84% / val_loss: 0.0542, val_accuracy: 98.29%\n",
      "Epoch [15] train_loss: 0.0421, train_accuracy: 98.89% / val_loss: 0.0573, val_accuracy: 98.18%\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(trainloader) # 전체 mini batch 개수\n",
    "val_total_batch = len(testloader)\n",
    "\n",
    "for epoch in range(1, 1+num_epoch):\n",
    "    # Train\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    num_total_data = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        X = images.to(device)\n",
    "        X = X.reshape(batch_size, 1, 28, 28)\n",
    "        \n",
    "        Y = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # graident 초기화\n",
    "        \n",
    "        prediction = model(X)\n",
    "        loss = loss_function(prediction, Y.long())\n",
    "        \n",
    "        loss.backward() # backpropgation\n",
    "        optimizer.step() # update weight\n",
    "        \n",
    "        avg_loss += loss.item()/total_batch\n",
    "        \n",
    "        prediction_softmax =  F.softmax(prediction, dim=1)\n",
    "        prediction_class = torch.argmax(prediction_softmax, dim=1)\n",
    "        \n",
    "        correct += (prediction_class == Y).sum().item()\n",
    "        num_total_data += len(labels)\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_avg_loss = 0\n",
    "        val_correct = 0\n",
    "        val_num_total_data = 0\n",
    "        \n",
    "        for batch_idx, (val_images, val_labels) in enumerate(testloader):\n",
    "            val_X = val_images.to(device)\n",
    "            val_X = val_X.reshape(batch_size, 1, 28, 28)\n",
    "            val_Y = val_labels.to(device)\n",
    "            \n",
    "            val_prediction = model(val_X)\n",
    "            val_loss = loss_function(val_prediction, val_Y.long())\n",
    "            val_avg_loss += val_loss.item()/val_total_batch\n",
    "            \n",
    "            val_prediction_softmax = F.softmax(val_prediction, dim=1)\n",
    "            val_prediction_class = torch.argmax(val_prediction_softmax, dim=1)\n",
    "            \n",
    "            val_correct += (val_prediction_class == val_Y).sum().item()\n",
    "            val_num_total_data += len(val_labels)\n",
    "            \n",
    "    \n",
    "        \n",
    "    print(f\"Epoch [{epoch}] train_loss: {avg_loss:.4f}, train_accuracy: {correct/num_total_data*100:.2f}%\", end=' / ')\n",
    "    print(f\"val_loss: {val_avg_loss:.4f}, val_accuracy: {val_correct/val_num_total_data*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467866a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 저장 하고 불러오기\n",
    "## torch.save(model.state_dict(), PATH)\n",
    "## model = CNN().to(device)\n",
    "## model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
